spark.myapp.input=data/in
spark.myapp.output=data/out
#spark.myapp.input=gs://my-demo-bucket/in
#spark.myapp.output=gs://my-demo-bucket/out

# MySQL
spark.mysql.host=mysql
spark.mysql.port=3306
spark.mysql.username=root
spark.mysql.password=root

# Spark
spark.logConf=true
spark.sql.parquet.compression.codec=snappy
spark.sql.parquet.filterPushdown=true

### Google Cloud Storage ###

# The AbstractFileSystem for 'gs:' URIs
spark.hadoop.fs.AbstractFileSystem.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem

# Optional. Google Cloud Project ID with access to GCS buckets.
# Required only for list buckets and create bucket operations.
spark.hadoop.fs.gs.project.id=

# Whether to use a service account for GCS authorization. Setting this
# property to `false` will disable use of service accounts for authentication.
spark.hadoop.google.cloud.auth.service.account.enable=true

# The JSON keyfile of the service account used for GCS
# access when google.cloud.auth.service.account.enable is true.
spark.hadoop.google.cloud.auth.service.account.json.keyfile=/path/to/keyfile








spark.yarn.maxAppAttempts=1
spark.dynamicAllocation.minExecutors=1
spark.dynamicAllocation.maxExecutors=5
spark.executor.memoryOverhead=1G
